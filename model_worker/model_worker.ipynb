{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from api_models import get_models, ModelListResponse,ModelPermission,Model\n",
    "response: ModelListResponse = await get_models()\n",
    "model: Model = response.data[0]\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TheBloke/Phind-CodeLlama-34B-v2-AWQ',\n",
       " 'object': 'model',\n",
       " 'created': 1698504990,\n",
       " 'owned_by': 'vllm',\n",
       " 'root': 'TheBloke/Phind-CodeLlama-34B-v2-AWQ',\n",
       " 'parent': None,\n",
       " 'permission': [{'id': 'modelperm-21503e4bd75d4eb09c8515fc82d8942e',\n",
       "   'object': 'model_permission',\n",
       "   'created': 1698504990,\n",
       "   'allow_create_engine': False,\n",
       "   'allow_sampling': True,\n",
       "   'allow_logprobs': True,\n",
       "   'allow_search_indices': False,\n",
       "   'allow_view': True,\n",
       "   'allow_fine_tuning': False,\n",
       "   'organization': '*',\n",
       "   'group': None,\n",
       "   'is_blocking': False}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vllm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/jphillips/fearnworks/aidriver/model_worker/model_worker.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jphillips/fearnworks/aidriver/model_worker/model_worker.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mapi_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m wrap_and_print,  get_default_sample_params, generate\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jphillips/fearnworks/aidriver/model_worker/model_worker.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/jphillips/fearnworks/aidriver/model_worker/model_worker.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m prompt \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mSan Francisco is a\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# Note: prompt is a list\u001b[39;00m\n",
      "File \u001b[0;32m~/fearnworks/aidriver/model_worker/api_utils.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtextwrap\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvllm\u001b[39;00m \u001b[39mimport\u001b[39;00m SamplingParams\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List \n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vllm'"
     ]
    }
   ],
   "source": [
    "from api_utils import wrap_and_print,  get_default_sample_params, generate\n",
    "import json \n",
    "prompt = [\"San Francisco is a\"]  # Note: prompt is a list\n",
    "params: SamplingParams = get_default_sample_params()\n",
    "logger.info(params)\n",
    "async for completion in generate(params, \"ehartford/dolphin-2.1-mistral-7b\", prompt):\n",
    "    print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING MODEL : TheBloke/Phind-CodeLlama-34B-v2-AWQ\n",
      "To sort a list of numbers in ascending order in Python, you can use the built-in sorted() function. Here is how you can create a Python script for this task:\n",
      "\n",
      "```python\n",
      "def sort_numbers(numbers):\n",
      "    return sorted(numbers)\n",
      "\n",
      "# Use example\n",
      "numbers = [67, 23, 34, 2, 89, 23, 2]\n",
      "sorted_numbers = sort_numbers(numbers)\n",
      "print(sorted_numbers)\n",
      "```\n",
      "\n",
      "In this script, we first define a function named sort_numbers that takes a list named numbers as a parameter. Inside the function, we return the result of the sorted() function called with numbers as the argument.\n",
      "\n",
      "Then we create a list of numbers and use the sort_numbers function to sort the list, printing the sorted list to the console. The sorted() function doesn't modify the original list; it returns a new list that contains the sorted numbers.\n",
      "\n",
      "The printed result will be:\n",
      "\n",
      "```[2, 2, 23, 23, 34, 67, 89]```\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "openai.api_key = \"EMPTY\"\n",
    "openai.api_base = \"http://127.0.0.1:8100/v1\"\n",
    "import asyncio\n",
    "from openai_streaming import process_response\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "# Define content handler\n",
    "async def content_handler(content: AsyncGenerator[str, None]):\n",
    "    async for token in content:\n",
    "        print(token, end=\"\")\n",
    "\n",
    "print(f\"USING MODEL : {model['id']}\")\n",
    "description = \"Create a Python script to sort a list of numbers in ascending order.\"\n",
    "response = openai.Completion.create(\n",
    "  model=model[\"id\"],\n",
    "  prompt=f\"Code generation:\\n{description}\",\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "code = response.choices[0].text.strip()\n",
    "print(code)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 23, 23, 34, 67, 89]\n"
     ]
    }
   ],
   "source": [
    "def sort_numbers(numbers):\n",
    "    return sorted(numbers)\n",
    "\n",
    "# Use example\n",
    "numbers = [67, 23, 34, 2, 89, 23, 2]\n",
    "sorted_numbers = sort_numbers(numbers)\n",
    "print(sorted_numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
